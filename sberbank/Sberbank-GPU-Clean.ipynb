{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now that I have figured out how to install XGBoost as well as run it cleanly, this notebook will be a cleaned-up version of the previous notebook. I'm going to take out all of the exploratory stuff and go straight to the heart of the matter. I'm also going to clean up the imports, test and train data frames as well as the null columns using the train data set. Go line by line and make sure everything is straightforward and decently commented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The usual imports..\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import time                     # Using time to check how long it takes to train model\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train.csv', parse_dates=['timestamp'])\n",
    "test_df = pd.read_csv('./data/test.csv', parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30471, 292)\n",
      "(7662, 291)\n",
      "Index(['id', 'timestamp', 'full_sq', 'life_sq', 'floor', 'max_floor',\n",
      "       'material', 'build_year', 'num_room', 'kitch_sq',\n",
      "       ...\n",
      "       'cafe_count_5000_price_1500', 'cafe_count_5000_price_2500',\n",
      "       'cafe_count_5000_price_4000', 'cafe_count_5000_price_high',\n",
      "       'big_church_count_5000', 'church_count_5000', 'mosque_count_5000',\n",
      "       'leisure_count_5000', 'sport_count_5000', 'market_count_5000'],\n",
      "      dtype='object', length=291)\n",
      "Index(['id', 'timestamp', 'full_sq', 'life_sq', 'floor', 'max_floor',\n",
      "       'material', 'build_year', 'num_room', 'kitch_sq',\n",
      "       ...\n",
      "       'cafe_count_5000_price_2500', 'cafe_count_5000_price_4000',\n",
      "       'cafe_count_5000_price_high', 'big_church_count_5000',\n",
      "       'church_count_5000', 'mosque_count_5000', 'leisure_count_5000',\n",
      "       'sport_count_5000', 'market_count_5000', 'price_doc'],\n",
      "      dtype='object', length=292)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(test_df.columns)\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                           0\n",
       "timestamp                                    0\n",
       "full_sq                                      0\n",
       "life_sq                                   6383\n",
       "floor                                      167\n",
       "max_floor                                 9572\n",
       "material                                  9572\n",
       "build_year                               13605\n",
       "num_room                                  9572\n",
       "kitch_sq                                  9572\n",
       "state                                    13559\n",
       "product_type                                 0\n",
       "sub_area                                     0\n",
       "area_m                                       0\n",
       "raion_popul                                  0\n",
       "green_zone_part                              0\n",
       "indust_part                                  0\n",
       "children_preschool                           0\n",
       "preschool_quota                           6688\n",
       "preschool_education_centers_raion            0\n",
       "children_school                              0\n",
       "school_quota                              6685\n",
       "school_education_centers_raion               0\n",
       "school_education_centers_top_20_raion        0\n",
       "hospital_beds_raion                      14441\n",
       "healthcare_centers_raion                     0\n",
       "university_top_20_raion                      0\n",
       "sport_objects_raion                          0\n",
       "additional_education_raion                   0\n",
       "culture_objects_top_25                       0\n",
       "                                         ...  \n",
       "big_church_count_3000                        0\n",
       "church_count_3000                            0\n",
       "mosque_count_3000                            0\n",
       "leisure_count_3000                           0\n",
       "sport_count_3000                             0\n",
       "market_count_3000                            0\n",
       "green_part_5000                              0\n",
       "prom_part_5000                             178\n",
       "office_count_5000                            0\n",
       "office_sqm_5000                              0\n",
       "trc_count_5000                               0\n",
       "trc_sqm_5000                                 0\n",
       "cafe_count_5000                              0\n",
       "cafe_sum_5000_min_price_avg                297\n",
       "cafe_sum_5000_max_price_avg                297\n",
       "cafe_avg_price_5000                        297\n",
       "cafe_count_5000_na_price                     0\n",
       "cafe_count_5000_price_500                    0\n",
       "cafe_count_5000_price_1000                   0\n",
       "cafe_count_5000_price_1500                   0\n",
       "cafe_count_5000_price_2500                   0\n",
       "cafe_count_5000_price_4000                   0\n",
       "cafe_count_5000_price_high                   0\n",
       "big_church_count_5000                        0\n",
       "church_count_5000                            0\n",
       "mosque_count_5000                            0\n",
       "leisure_count_5000                           0\n",
       "sport_count_5000                             0\n",
       "market_count_5000                            0\n",
       "price_doc                                    0\n",
       "Length: 292, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                       0\n",
       "timestamp                                0\n",
       "full_sq                                  0\n",
       "life_sq                                  0\n",
       "floor                                    0\n",
       "max_floor                                0\n",
       "material                                 0\n",
       "build_year                               0\n",
       "num_room                                 0\n",
       "kitch_sq                                 0\n",
       "state                                    0\n",
       "product_type                             0\n",
       "sub_area                                 0\n",
       "area_m                                   0\n",
       "raion_popul                              0\n",
       "green_zone_part                          0\n",
       "indust_part                              0\n",
       "children_preschool                       0\n",
       "preschool_quota                          0\n",
       "preschool_education_centers_raion        0\n",
       "children_school                          0\n",
       "school_quota                             0\n",
       "school_education_centers_raion           0\n",
       "school_education_centers_top_20_raion    0\n",
       "hospital_beds_raion                      0\n",
       "healthcare_centers_raion                 0\n",
       "university_top_20_raion                  0\n",
       "sport_objects_raion                      0\n",
       "additional_education_raion               0\n",
       "culture_objects_top_25                   0\n",
       "                                        ..\n",
       "big_church_count_3000                    0\n",
       "church_count_3000                        0\n",
       "mosque_count_3000                        0\n",
       "leisure_count_3000                       0\n",
       "sport_count_3000                         0\n",
       "market_count_3000                        0\n",
       "green_part_5000                          0\n",
       "prom_part_5000                           0\n",
       "office_count_5000                        0\n",
       "office_sqm_5000                          0\n",
       "trc_count_5000                           0\n",
       "trc_sqm_5000                             0\n",
       "cafe_count_5000                          0\n",
       "cafe_sum_5000_min_price_avg              0\n",
       "cafe_sum_5000_max_price_avg              0\n",
       "cafe_avg_price_5000                      0\n",
       "cafe_count_5000_na_price                 0\n",
       "cafe_count_5000_price_500                0\n",
       "cafe_count_5000_price_1000               0\n",
       "cafe_count_5000_price_1500               0\n",
       "cafe_count_5000_price_2500               0\n",
       "cafe_count_5000_price_4000               0\n",
       "cafe_count_5000_price_high               0\n",
       "big_church_count_5000                    0\n",
       "church_count_5000                        0\n",
       "mosque_count_5000                        0\n",
       "leisure_count_5000                       0\n",
       "sport_count_5000                         0\n",
       "market_count_5000                        0\n",
       "price_doc                                0\n",
       "Length: 292, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.fillna(train_df.mean())\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, to determine whether the test set has missing data, and how well it matches up with the training set. I hope to fill any missing data with the mean from the training set. To remind myself:\n",
    "train_df - full data frame of training data\n",
    "\n",
    "X_train - 80% sample of the training data\n",
    "\n",
    "X_valid - 20% sample of training data (cross-validation set)\n",
    "\n",
    "test_df - full data frame of the test data. (no labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Investment       19448\n",
       "OwnerOccupier    11023\n",
       "Name: product_type, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_df[test_df.isnull()].dtypes\n",
    "train_df['product_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We see that there is roughly an even split between investment and owneroccupier in the training data.\n",
    "# I'll fill the test data frame missing values with \"Investment\" and move forward\n",
    "test_df['product_type'].fillna('Investment', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zjuzino'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['sub_area'].values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                       0\n",
       "timestamp                                0\n",
       "full_sq                                  0\n",
       "life_sq                                  0\n",
       "floor                                    0\n",
       "max_floor                                0\n",
       "material                                 0\n",
       "build_year                               0\n",
       "num_room                                 0\n",
       "kitch_sq                                 0\n",
       "state                                    0\n",
       "product_type                             0\n",
       "sub_area                                 0\n",
       "area_m                                   0\n",
       "raion_popul                              0\n",
       "green_zone_part                          0\n",
       "indust_part                              0\n",
       "children_preschool                       0\n",
       "preschool_quota                          0\n",
       "preschool_education_centers_raion        0\n",
       "children_school                          0\n",
       "school_quota                             0\n",
       "school_education_centers_raion           0\n",
       "school_education_centers_top_20_raion    0\n",
       "hospital_beds_raion                      0\n",
       "healthcare_centers_raion                 0\n",
       "university_top_20_raion                  0\n",
       "sport_objects_raion                      0\n",
       "additional_education_raion               0\n",
       "culture_objects_top_25                   0\n",
       "                                        ..\n",
       "cafe_count_3000_price_high               0\n",
       "big_church_count_3000                    0\n",
       "church_count_3000                        0\n",
       "mosque_count_3000                        0\n",
       "leisure_count_3000                       0\n",
       "sport_count_3000                         0\n",
       "market_count_3000                        0\n",
       "green_part_5000                          0\n",
       "prom_part_5000                           0\n",
       "office_count_5000                        0\n",
       "office_sqm_5000                          0\n",
       "trc_count_5000                           0\n",
       "trc_sqm_5000                             0\n",
       "cafe_count_5000                          0\n",
       "cafe_sum_5000_min_price_avg              0\n",
       "cafe_sum_5000_max_price_avg              0\n",
       "cafe_avg_price_5000                      0\n",
       "cafe_count_5000_na_price                 0\n",
       "cafe_count_5000_price_500                0\n",
       "cafe_count_5000_price_1000               0\n",
       "cafe_count_5000_price_1500               0\n",
       "cafe_count_5000_price_2500               0\n",
       "cafe_count_5000_price_4000               0\n",
       "cafe_count_5000_price_high               0\n",
       "big_church_count_5000                    0\n",
       "church_count_5000                        0\n",
       "mosque_count_5000                        0\n",
       "leisure_count_5000                       0\n",
       "sport_count_5000                         0\n",
       "market_count_5000                        0\n",
       "Length: 291, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in test_df.columns:\n",
    "    if test_df[col].isnull().sum() != 0:\n",
    "        test_df[col] = test_df[col].fillna(train_df[col].mean())\n",
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, it looks like I took care of the null values in the test dataframe. All I had to do was sort out the product_type column, it seems. I'll take it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saw this interesting method to create a cross validation set from a single data frame. \n",
    "df2split = train_df\n",
    "msk = np.random.rand(len(df2split)) < 0.8\n",
    "X_train = df2split[msk]\n",
    "y_train = X_train.price_doc\n",
    "X_valid = df2split[~msk]\n",
    "y_valid = X_valid.price_doc\n",
    "#X_train = X_train.drop('price_doc', axis=1)  #Not sure if I should drop the labels from train / validation sets.\n",
    "#X_valid = X_valid.drop('price_doc', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24318, 292)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6153, 292)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up some global variables for cleaning up the data\n",
    "target = 'price_doc'\n",
    "IDcol = 'id'\n",
    "timestamp = 'timestamp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.drop('timestamp', axis=1)\n",
    "test_df = test_df.drop('timestamp', axis=1)\n",
    "train_df = train_df.drop('timestamp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24318, 291)\n",
      "(30471, 291)\n",
      "(7662, 290)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clear up the categorical variables and create dummy columns of the categorical variables\n",
    "s = train_df.dtypes\n",
    "object_columns = s[s.values == 'object'].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Continue with cleaning up categorical stuff.\n",
    "for i in object_columns:\n",
    "    train_df[i] = train_df[i].astype('category')\n",
    "    X_train[i] = X_train[i].astype('category')\n",
    "    test_df[i] = test_df[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create dummy variables for the categorical columns\n",
    "train_df = pd.get_dummies(train_df)\n",
    "X_train = pd.get_dummies(X_train)\n",
    "test_df = pd.get_dummies(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'price_doc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2f6c60e9f8e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Prep the train dataframe for xgboost... it is a quirky model..\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice_doc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIDcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/charlierock/anaconda3/envs/py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2969\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2970\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2972\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'price_doc'"
     ]
    }
   ],
   "source": [
    "# Prep the train dataframe for xgboost... it is a quirky model..\n",
    "label = train_df.price_doc\n",
    "predictors = [x for x in train_df.columns if x not in [target, IDcol]]\n",
    "train_df = train_df[predictors]\n",
    "dtrain = train_df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'poor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3f6531f5e737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnum_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mxgtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/charlierock/anaconda3/envs/py36/lib/python3.6/site-packages/xgboost-0.6-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_npy2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/charlierock/anaconda3/envs/py36/lib/python3.6/site-packages/xgboost-0.6-py3.6.egg/xgboost/core.py\u001b[0m in \u001b[0;36m_init_from_npy2d\u001b[0;34m(self, mat, missing)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# we try to avoid data copies if possible (reshape returns a view when possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;31m# and we explicitly tell np.array to try and avoid copying)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'poor'"
     ]
    }
   ],
   "source": [
    "# Set up the parameter dictionary for xgboost\n",
    "params = {}\n",
    "params['eta'] = 0.1\n",
    "params['objective'] = 'reg:linear'\n",
    "params['max_depth'] = 5\n",
    "params['min_child_weight'] = 1\n",
    "params['gamma'] = 0\n",
    "params['eval_metric'] = 'mae'\n",
    "params['updater'] = 'grow_gpu'\n",
    "\n",
    "num_round = 20\n",
    "xgtrain = xgb.DMatrix(dtrain, label=label)\n",
    "tmp = time.time()\n",
    "bst = xgb.train(params, xgtrain, num_round)\n",
    "boost_time = time.time() - tmp\n",
    "print('Train time: %s sec' % (str(boost_time)))\n",
    "xgb.plot_importance(bst, max_num_features=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgtest = xgb.DMatrix(test_df)\n",
    "preds = bst.predict(xgtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
