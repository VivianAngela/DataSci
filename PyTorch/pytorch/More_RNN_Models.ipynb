{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model B: 2 Hidden Layer (w. ReLU)\n",
    "* Unroll 28 time steps\n",
    "    * Each step input size 28 x 1\n",
    "    * Total per unroll: 28 x 28\n",
    "        * Feedforward Neural Network input size: 28 x 28\n",
    "* **2 Hidden Layer**\n",
    "* ReLU activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "* STEP 1: Load dataset\n",
    "* STEP 2: Make dataset iterable\n",
    "* STEP 3: Create model class\n",
    "* **STEP 4: Instantiate model class**\n",
    "* STEP 5: Instantiate loss class\n",
    "* STEP 6: Instantiate optimizer class\n",
    "* STEP 7: Train Model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel (\n",
      "  (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
      "  (fc): Linear (100 -> 10)\n",
      ")\n",
      "10\n",
      "torch.Size([100, 28])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "Iteration: 500. Loss: 1.021502137184143. Accuracy: 62.14\n",
      "Iteration: 1000. Loss: 0.6722710132598877. Accuracy: 73.9\n",
      "Iteration: 1500. Loss: 0.24204854667186737. Accuracy: 91.98\n",
      "Iteration: 2000. Loss: 0.31326016783714294. Accuracy: 93.07\n",
      "Iteration: 2500. Loss: 2.313302993774414. Accuracy: 11.35\n",
      "Iteration: 3000. Loss: 2.301129102706909. Accuracy: 11.35\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 1: Load Dataset\n",
    "'''\n",
    "train_dataset = dsets.MNIST(root=\"./data\",\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(), \n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "'''\n",
    "STEP 2: Make Dataset Iterable\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = int(n_iters / (len(train_dataset)/batch_size))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "'''\n",
    "STEP 3: Create Model Class\n",
    "'''\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your RNN\n",
    "        # batch_first=True causes input/output Tensors to be of shape\n",
    "        # (batch_dim, seq_dim, input_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout Layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: Instantiate Model Class\n",
    "'''\n",
    "\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 2   # This is the only change to add another hidden layer to the model! Simple! \n",
    "output_dim = 10\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# Printing model and parameters to illustrate the difference with our 2 hidden layer neural network\n",
    "\n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "    \n",
    "'''\n",
    "STEP 5: Instantiate Loss Class\n",
    "'''\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "'''\n",
    "STEP 6: Instantiate Optimizer Class\n",
    "'''\n",
    "\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: Train the Model\n",
    "'''\n",
    "\n",
    "# Number of steps to unroll\n",
    "seq_dim = 28\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "    \n",
    "        images = Variable(images.view(-1, seq_dim, input_dim)) \n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward pass to get outputs / logits\n",
    "        # outputs.size() --> (100, 10)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #Calculate Loss: softmax --> Cross Entropy Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #Get gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0 \n",
    "            total = 0\n",
    "            #Iterate through the test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to Torch Variable\n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                \n",
    "                # Forward pass only to get outputs/logits\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                    \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weird, my loss is NaN. Something strange going on here, despite me copying / pasting the code over from the previous model. I think it was getting confused because of the re-use of variable names, etc. After shutting down the notebooks and restarting, it looks like I'm getting positive results, which mirror the instructor's results. Strange, It bombed out at 2500 iterations, going from 93% accuracy to this 11.35% number... I'm going to move on for now, but come back later to figure out why the loss balloons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **10 sets of parameters** \n",
    "* First Hidden Layer\n",
    "    * $A_1 = [100,28]$\n",
    "    * $A_3 = [100,100]$\n",
    "    * $B_1 = [100]$\n",
    "    * $B_3 = [100]$\n",
    "* Second Hidden Layer\n",
    "    * $A_2 = [100,100]$\n",
    "    * $A_5 = [100,100]$\n",
    "    * $B_2 = [100]$\n",
    "    * $B_5 = [100]$\n",
    "* Readout Layer\n",
    "    * $A_5 = [10,100]$\n",
    "    * $B_5 = [10]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model B: 2 Hidden Layer (w. ReLU)\n",
    "* Unroll 28 time steps\n",
    "    * Each step input size 28 x 1\n",
    "    * Total per unroll: 28 x 28\n",
    "        * Feedforward Neural Network input size: 28 x 28\n",
    "* **2 Hidden Layer**\n",
    "* Tanh activation function\n",
    "### Steps\n",
    "* STEP 1: Load dataset\n",
    "* STEP 2: Make dataset iterable\n",
    "* **STEP 3: Create model class**\n",
    "* STEP 4: Instantiate model class\n",
    "* STEP 5: Instantiate loss class\n",
    "* STEP 6: Instantiate optimizer class\n",
    "* STEP 7: Train Model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNModel (\n",
      "  (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
      "  (fc): Linear (100 -> 10)\n",
      ")\n",
      "10\n",
      "torch.Size([100, 28])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100])\n",
      "torch.Size([100])\n",
      "torch.Size([10, 100])\n",
      "torch.Size([10])\n",
      "Iteration: 500. Loss: 0.4070070683956146. Accuracy: 84.93\n",
      "Iteration: 1000. Loss: 0.3393940031528473. Accuracy: 91.68\n",
      "Iteration: 1500. Loss: 0.2780081629753113. Accuracy: 92.05\n",
      "Iteration: 2000. Loss: 0.17639566957950592. Accuracy: 94.96\n",
      "Iteration: 2500. Loss: 0.111669160425663. Accuracy: 95.99\n",
      "Iteration: 3000. Loss: 0.101287841796875. Accuracy: 95.93\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 3: Create Model Class\n",
    "'''\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        # Hidden Dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # Building your RNN\n",
    "        # batch_first=True causes input/output Tensors to be of shape\n",
    "        # (batch_dim, seq_dim, input_dim)\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='tanh')\n",
    "        \n",
    "        # Readout Layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        # (layer_dim, batch_size, hidden_dim)\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "        \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        \n",
    "        # Index hidden state of last time step\n",
    "        # out.size() --> 100, 28, 100\n",
    "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        # out.size() --> 100, 10\n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: Instantiate Model Class\n",
    "'''\n",
    "\n",
    "input_dim = 28\n",
    "hidden_dim = 100\n",
    "layer_dim = 2   # This is the only change to add another hidden layer to the model! Simple! \n",
    "output_dim = 10\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# Printing model and parameters to illustrate the difference with our 2 hidden layer neural network\n",
    "\n",
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "for i in range(len(list(model.parameters()))):\n",
    "    print(list(model.parameters())[i].size())\n",
    "    \n",
    "'''\n",
    "STEP 5: Instantiate Loss Class\n",
    "'''\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "'''\n",
    "STEP 6: Instantiate Optimizer Class\n",
    "'''\n",
    "\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "'''\n",
    "STEP 7: Train the Model\n",
    "'''\n",
    "\n",
    "# Number of steps to unroll\n",
    "seq_dim = 28\n",
    "\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "    \n",
    "        images = Variable(images.view(-1, seq_dim, input_dim)) \n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward pass to get outputs / logits\n",
    "        # outputs.size() --> (100, 10)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #Calculate Loss: softmax --> Cross Entropy Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #Get gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0 \n",
    "            total = 0\n",
    "            #Iterate through the test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to Torch Variable\n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                \n",
    "                # Forward pass only to get outputs/logits\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                    \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Results \n",
    "\n",
    "**Model A** | **Model B** | **Model C**\n",
    "--- | --- | ---\n",
    "ReLU | ReLU | tanH\n",
    "1 Hidden Layer | 2 Hidden Layers | 2 Hidden Layers\n",
    "100 Hidden Units | 100 Hidden Units | 100 Hidden Units\n",
    "~92.2% | ~95.0% | ~95.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning\n",
    "\n",
    "* 2 ways to expand a recurrent neural network\n",
    "    * More non-linear activations units (neurons)\n",
    "    * More hidden layers\n",
    "* Cons\n",
    "    * Need a larger dataset\n",
    "        * Curse of dimensionality\n",
    "    * Does not necessarily mean higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
