{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Feedforward NN Transition to Convolutional Neural Networks\n",
    "\n",
    "[Graphic illustrating 1 hidden layer feed forward neural network]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Convolutional Neural Network\n",
    "\n",
    "* Add Convolution and Pooling layers before the feedforward neural network\n",
    "* Layer with linear function & non-linearity: **fully connected layer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. One Convolutional Layer: High Level View\n",
    "\n",
    "More diagrams that I can't recreate. I can always refer to the lectures if need be. \n",
    "* Input Depth = 1: **grayscale image**\n",
    "* Convolution is like mapping from your input layer to a matrix of numbers as output. This is called a feature map, or activation map. \n",
    "* Each filter or kernel takes **strides** across your image, and the output of each stride adds a digit to the feature map\n",
    "* This is the basis of those cool demos that show which filters get activated when a CNN \"looks\" at input images. The filters (or kernels) are receptive to different features (horizontal lines, curves, circles, edges, etc.)\n",
    "* Filter $\\cdot$ pixel data in the receptive field = each data point in the feature map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Depth of 3: One Convolutional Layer\n",
    "\n",
    "* Input depth = 1: **grayscale**\n",
    "* Input depth = 3: **color (RGB)**\n",
    "* Filter / Kernel must have the same depth as the input depth of your image. (Matrix multiplication req't)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level Summary: One Convolutional Layer\n",
    "* As the kernel is sliding/convolving across the image $\\to$ 2 operations done **per patch**\n",
    "    1. Element-wise multiplication\n",
    "    - Summation\n",
    "* More kernels = more feature map channels\n",
    "    * Can capture more information about the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Multiple Convolutional Layers: High Level View\n",
    "* After a convolutional layer, there is usually a pooling / downsampling layer.\n",
    "* Subsequent convolutional layers can have more kernels, allowing us to learn more about the image, going deeper and deeper into the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Pooling Layers: High Level View\n",
    "* 2 Common Types\n",
    "    1. Max Pooling\n",
    "    - Average Pooling\n",
    "* Question: Does having pooling layers help prevent overfitting? i.e. Does it make the model better able to generalize\n",
    "* Pooling uses a kernel of its own, sliding it across the feature map created in the convolutional layer. The kernel takes the max (or average) value inside the kernel at each stride. This is why the subsequent layer is downsampled. Only taking one number per stride. Size of kernel determines how much the layer downsamples. \n",
    "* Can go on with convolution-pooling-convolution-pooling forever. That's the essence of \"Deep\" learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Padding\n",
    "* Method to either preserve or modify the size of the image from input to feature map. \n",
    "* Types\n",
    "    * Valid Padding (zero padding) Output size < Input size\n",
    "    * Same Padding (non-zero padding) Output size = Input size. Adds zeros around the image as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8. Dimension Calculations\n",
    "* $O=\\frac{W-K+2P}{S}+1$\n",
    "    * $O$: output height/length\n",
    "    * $W$: input height/length\n",
    "    * $K$: filter size / kernel size\n",
    "    * $P$: padding\n",
    "        * $P=\\frac{K-1}2$\n",
    "    * $S$: stride"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a Convolutional Neural Network with PyTorch\n",
    "* Here we go! \n",
    "### Model A:\n",
    "* 2 Convolutional Layers\n",
    "    * Same Padding: output size = input size\n",
    "* 2 Max Pooling Layers\n",
    "* 1 Fully Connected Layer\n",
    "\n",
    "### Steps\n",
    "* STEP 1: Load dataset\n",
    "* STEP 2: Make dataset iterable\n",
    "* STEP 3: Create model class\n",
    "* STEP 4: Instantiate model class\n",
    "* STEP 5: Instantiate loss class\n",
    "* STEP 6: Instantiate optimizer class\n",
    "* Step 7: Train Model! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(root=\"./data\",\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(), \n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.train_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.test_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.test_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Make dataset iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = int(n_iters / (len(train_dataset)/batch_size))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Model Class (Herein lies the good stuff!)\n",
    "\n",
    "* $O=\\frac{W-K+2P}{S}+1$\n",
    "    * $O$: output height/length\n",
    "    * $W$: input height/length\n",
    "    * $K$: filter size / kernel size: **5**\n",
    "    * $P$: padding: **same padding (non-zero)**\n",
    "        * $P=\\frac{K-1}2=\\frac{5-1}2=2$\n",
    "    * $S$: stride: **=1**\n",
    "**Output size for Max Pooling**\n",
    "* $O=\\frac WK$\n",
    "    * $W$: Input height/width\n",
    "    * $K$: **filter size = 2** (downsamples to half input size, i.e. 2 in the denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above two equations will give us the numbers we need as we build our model. \n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # Max Pooling 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # Max Pooling 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        out = self.relu1(out)\n",
    "        \n",
    "        # Max Pooling 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        # Convolution 2\n",
    "        out = self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        \n",
    "        # Max Pooling 2\n",
    "        out = self.maxpool2(out)\n",
    "        \n",
    "        # Resize for the linear function in the readout layer\n",
    "        # Original size: (100, 32, 7, 7)\n",
    "        # out.size(0): 100\n",
    "        # Desired out size: (100, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)  #I might need to look into this to see what is going on under the hood\n",
    "        \n",
    "        # Linear Function (readout) Layer\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Instantiate Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Instantiate Loss Class\n",
    "* Convolutional Neural Network: **Cross Entropy Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Instantiate Optimizer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-depth Look at Our Model's Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x1152f6570>\n",
      "6\n",
      "torch.Size([16, 1, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([32, 16, 5, 5])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 1568])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(model.parameters())\n",
    "print(len(list(model.parameters()))) #This will show us how many items are in our list of parameters (trainable layers)\n",
    "\n",
    "# Convolution 1: 16 kernels\n",
    "print(list(model.parameters())[0].size())\n",
    "\n",
    "# Convolution 1 bias: 16 kernels\n",
    "print(list(model.parameters())[1].size())\n",
    "\n",
    "# Convolution 2: 32 kernels with depth = 16\n",
    "print(list(model.parameters())[2].size())\n",
    "\n",
    "# Convolution 2 bias: 32 kernels with depth = 16\n",
    "print(list(model.parameters())[3].size())\n",
    "\n",
    "# Fully Connected Layer 1\n",
    "print(list(model.parameters())[4].size())\n",
    "\n",
    "# Fully Connected Layer 1 Bias: \n",
    "print(list(model.parameters())[5].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the model!!\n",
    "\n",
    "#### Process\n",
    "1. **Convert inputs & labels to Variables**\n",
    "    * CNN Input: (1, 28, 28) CNN can take in a 2-dimensional tensor (28 by 28)\n",
    "    * Feedforward input: (1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 0.31840232014656067. Accuracy: 90.05\n",
      "Iteration: 1000. Loss: 0.16880546510219574. Accuracy: 93.02\n",
      "Iteration: 1500. Loss: 0.2797934412956238. Accuracy: 94.54\n",
      "Iteration: 2000. Loss: 0.3394652307033539. Accuracy: 95.7\n",
      "Iteration: 2500. Loss: 0.16251006722450256. Accuracy: 96.39\n",
      "Iteration: 3000. Loss: 0.07263852655887604. Accuracy: 97.07\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "    \n",
    "        images = Variable(images) #No need to resize, because the image is already in a form that the CNN can use.\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #Forward pass to get outputs / logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        #Calculate Loss: softmax --> Cross Entropy Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #Get gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        if iter % 500 == 0:\n",
    "            # Calculate Accuracy\n",
    "            correct = 0 \n",
    "            total = 0\n",
    "            #Iterate through the test dataset\n",
    "            for images, labels in test_loader:\n",
    "                # Load images to Torch Variable\n",
    "                images = Variable(images)\n",
    "                \n",
    "                # Forward pass only to get outputs/logits\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                # Total correct predictions\n",
    "                correct += (predicted == labels).sum()\n",
    "                    \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this model is extremely accurate after just 5 epochs. One thing to note though, is that training took considerably longer than previous models. I imagine the CNN is just that much more complex than previous models. The speedup on GPU will likely be very noticeable. Going to move to a new notebook for the exploration of different CNN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
