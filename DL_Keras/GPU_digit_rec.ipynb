{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "I found this program tutorial via the Data Machina mailing list. It is\n",
    "    Deep Leaning tutorial using the Keras & Theano packages on the MNIST\n",
    "    hand-written digits data set. Quite serendipitous, as I was planning\n",
    "    on working on this data set as my next project! The website is:\n",
    "    http://elitedatascience.com/keras-tutorial-deep-learning-in-python\n",
    "    Let's gooooo \n",
    "</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file is an update of the program below. Instead of using Theano, I'm planning on using tensorFlow. On top of that, this will be the first real test of my new GPU (GTX 1060 6GB) machine learning computer :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Package imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.misc import imread\n",
    "#This is simply a linear stack of neural network layers, and it's perfect for the type of feed-forward CNN we're building in this tutorial.\n",
    "from keras.models import Sequential\n",
    "# These are the layers that are used in almost any neural network:\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "#These are the convolutional layers that will help us efficiently train on image data:\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "#helpful utilities\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(123) #For reproducability with the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "root_dir = os.path.abspath('./')\n",
    "data_dir = os.path.join(root_dir, 'data')\n",
    "sub_dir = os.path.join(root_dir, 'sub')\n",
    "\n",
    "# check for existence\n",
    "os.path.exists(root_dir)\n",
    "os.path.exists(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, 'Train', 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir, 'Test_AV.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename  label\n",
       "0    0.png      4\n",
       "1    1.png      9\n",
       "2    2.png      1\n",
       "3    3.png      7\n",
       "4    4.png      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nocQPocQPocQPof4HgZE4ehliEwgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57f7079be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Using the Analytics Vidhya tutorial for a few inputs to parse the train / test data sets. \n",
    "rng = np.random.RandomState(123)\n",
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have successfully loaded our data, we can convert all of the images into numpy arrays for use in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape #Our image can be represented by a 28x28 numpy matrix, specifying pixel data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp1 = []\n",
    "for img_name in train.filename:\n",
    " image_path = os.path.join(data_dir, 'Train', 'Images', 'train', img_name)\n",
    " img = imread(image_path, flatten=True)\n",
    " img = img.astype('float32')\n",
    " temp1.append(img)\n",
    "\n",
    "train_x = np.stack(temp1)\n",
    "\n",
    "temp2 = []\n",
    "for img_name in test.filename:\n",
    " image_path = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)\n",
    " img = imread(image_path, flatten=True)\n",
    " img = img.astype('float32')\n",
    " temp2.append(img)\n",
    "\n",
    "test_x= np.stack(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not using Theano here. I want to use TensorFlow, so I'm not sure if the code below is valid. I might have to reshape my input data. Not going to be as straight forward as I thought.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(train_x.shape[0], 1, 28, 28)\n",
    "test_x = test_x.reshape(test_x.shape[0], 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 1, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x /= 255\n",
    "test_x /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#At this stage, I need to split the train data into a train set and a cross-validation set. I'm going to use a 75/25\n",
    "#split, what the hell. The original Keras tutorial I followed had a 60,000 digit training set, as well as a labeled\n",
    "#test set. Here, my test set is not labeled - aka that's what I am classifying!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_size = int(train_x.shape[0] * 0.75)\n",
    "\n",
    "train_x, cross_val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, cross_val_y = train_y[:split_size], train_y[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next up is to reshape the labels to categorical data, with the quick and easy .to_categorical function\n",
    "train_Y = np_utils.to_categorical(train_y, 10)\n",
    "cross_val_Y = np_utils.to_categorical(cross_val_y, 10) #notice we went to capital Y's for this change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36750, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12250, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>\n",
    "Now, we're ready to jump back to the original tutorial to build, train and evaluate our model. I'm not expecting as great a result (99.1% accuracy) because of the (much) smaller training set. But, that's the data I was given, so I have to work within those confines\n",
    "</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 26, 26)\n"
     ]
    }
   ],
   "source": [
    "#Declare a sequential model format\n",
    "model = Sequential()\n",
    "#Declare the input layer\n",
    "model.add(Convolution2D(32,3,3, activation='relu', input_shape=(1,28,28), dim_ordering='th'))\n",
    "#input shape corresponds to the shape of one sample, depth, width, height\n",
    "print(model.output_shape) #we get (None,-1,26,32) tutorial shows (None,32,26,26)\n",
    "#adding layers to our model like building lego\n",
    "model.add(Convolution2D(32,3,3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "#Dropout layer is a method of regularization (prevents over-fitting)\n",
    "#Now add fully connected Dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#Hard part is over - now we need to compile model and define loss function\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up next is training the model (cpu intensive due to the 10 epochs!) After that, I need to add some lines to demonstrate the predictions from my trained model. Getting pretty darn close! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_Y, batch_size=32, nb_epoch=25, verbose=0)\n",
    "#Finally, we evaluate this model on the test set, generating a score\n",
    "score = model.evaluate(cross_val_x, cross_val_Y, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.065963199032094577, 0.98873469387755097]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 1, 28, 28)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20672/21000 [============================>.] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 9, 7, 9, 6, 6, 7, 0, 4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come on you digits!! I managed to figure out how to create my predictions set. Now I just need to do some housekeeping, and maybe some fun visualization of a sample number or two. Well, I also want to train my model on more than one epoch. It is actually really good with just the one epoch, but it can get much better. Woohoo! The more I grind away at this stuff, the more confident I get. The real quantum leap will be when I get comfortable enough with the material to understand how to apply these tools to models of my own creation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niR9CiR9C/QujAMUenoXL1AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57f7921ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_name = rng.choice(test.filename)\n",
    "filepath = os.path.join(data_dir, 'Train', 'Images', 'test', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "test_index = int(img_name.split('.')[0]) - 49000\n",
    "print (\"Prediction is: \", predictions[test_index])\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Satisfied, it's time to create the submission file to put on the Analytics Viddhya site. Let's wrap this up, B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {'filename': test.filename, 'label':predictions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit_file = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49000.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49001.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49002.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49003.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49004.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename  label\n",
       "0  49000.png      4\n",
       "1  49001.png      0\n",
       "2  49002.png      9\n",
       "3  49003.png      7\n",
       "4  49004.png      9"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit_file.to_csv('CN_submit_GPU.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
